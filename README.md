# time-series-transformer

연간 데이콘 [인공지능 비트 트레이더 경진대회] 참가용 레포지토리입니다. 시계열 데이터를 예측할 수 있는 Transformer 기반 모델링 및 데이터 전처리에 대한 jupyter notebook이 있습니다🐶


[인공지능 비트 트레이더 경진대회]: https://dacon.io/competitions/official/235709/overview/description/

### 1일차
Convolution으로 시계열 정보를 서브샘플링하였음, (그냥 시계열 전체를 사용하면 일반적인 transformer(NLP나 Speech)의 구조에서 입력의 길이가 길어서 메모리를 너무 많이 사용하게됨...
활성화함수로 GeLU를 사용하여서 동일한 분포로 샘플링하도록 하였음. 여기서는 트랜스포머 디코더를 사용하여서 인코딩된 입력에서 출력될 정보를 매핑하도록 모델링하고, L1, MSE 그리고 RMSE를 써보았지만... 학습에 실패 => 디코딩 과정에서 똑같은 값만 출력됨(매핑의 문제라고 추측됨)
또한 코인의 비식별화 인덱스를 입력의 특징으로 그대로 사용하는 것이 아닌, 임베딩하여 인코딩된 코인 가격 정보와 결합되게 하였다. 아마 비식별화 인덱스로써 알트코인의 종류를 뽑아낼 수 있지 않을까한다.

다음 모델링은 입력 시퀀스를 출력 시퀀스에 매핑하여 예측할 길이를 충족하는 것이 아니라, 입력 시퀀스의 특징/시간 각각을 서브 샘플링하여 출력할 시퀀스의 길이를 맞출 수 있도록 모델링할 예정...
